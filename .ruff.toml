target-version = "py311"

line-length = 90

[lint]
select = [
    "B",        # flake8-bugbear
    "C4",       # flake8-comprehensions
    "C9",       # mccabe
    "D",        # pydocstyle
    "DTZ",      # flake8-datetimez
    "E", "W",   # pycodestyle
    "F",        # Pyflakes
    "I",        # isort
    "ICN",      # flake8-import-conventions
    "N",        # pep8-naming
    "PT",       # flake8-pytest-style
    "S",        # flake8-bandit
    "TID251",   # banned-api
    "UP",       # pyupgrade
    "T20",      # flake8-print

]

ignore = [
    "D10",  # missing docstrings
    "W191", "E111", "E114", "E117", "D206", "D300", "Q000", "Q001", "Q002", "Q003", "COM812", "COM819", "ISC001", "ISC002",  # clash with ruff formatter
]

extend-safe-fixes = [
    "D415",  # ends-in-punctuation
]

extend-unsafe-fixes = [
    "B905",  # zip-without-explicit-strict - we don't want to set `strict=False` automatically
]


[lint.per-file-ignores]
"__init__.py" = ["F401"]
"tests/*" = ["S101"]


[lint.mccabe]
max-complexity = 15


[lint.pydocstyle]
convention = "google"


[lint.pycodestyle]
max-line-length = 99  # ceil(1.1 * 90) makes `E501` equivalent to `B950`


[lint.isort]
section-order = ["future", "standard-library", "pyspark", "third-party", "first-party", "local-folder"]

[lint.isort.sections]
"pyspark" = ["pyspark"]


[lint.flake8-import-conventions]
banned-from = ["pyspark.sql.functions", "pyspark.sql.types"]

[lint.flake8-import-conventions.extend-aliases]
"pyspark.sql.functions" = "sf"
"pyspark.sql.types" = "st"


[lint.flake8-tidy-imports.banned-api]
"pytz".msg = "pytz functionality is now covered by the standard library, e.g., `datetime.timezone`"
